{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Ingestion and Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile testutility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "\n",
    "################\n",
    "# File Reading #\n",
    "################\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raghad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (10,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to read the file using panads:  13.105557918548584 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "start = time.time()\n",
    "df = pd.read_csv('sales_data.csv')\n",
    "end = time.time()\n",
    "print(\"Time it took to read the file using panads: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to read the file using Dask:  0.015810012817382812 sec\n"
     ]
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "start = time.time()\n",
    "dask_df = dd.read_csv('sales_data.csv')\n",
    "end = time.time()\n",
    "print(\"Time it took to read the file using Dask: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dask is more efficient on reading large datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'store_id', 'date', 'sales', 'revenue', 'stock', 'price',\n",
       "       'promo_type_1', 'promo_bin_1', 'promo_type_2', 'promo_bin_2',\n",
       "       'promo_discount_2', 'promo_discount_type_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'store_id', 'date', 'sales', 'revenue', 'stock', 'price',\n",
       "       'promo_type_1', 'promo_bin_1', 'promo_type_2', 'promo_bin_2',\n",
       "       'promo_discount_2', 'promo_discount_type_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=df.columns.str.replace('[#,@,&]','')\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAML file Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "file_name: sales_data\n",
    "inbound_delimiter: \",\"\n",
    "columns: \n",
    "    - product_id\n",
    "    - store_id\n",
    "    - date\n",
    "    - sales\n",
    "    - revenue\n",
    "    - stock\n",
    "    - price\n",
    "    - promo_type_1\n",
    "    - promo_bin_1\n",
    "    - promo_type_2\n",
    "    - promo_bin_2\n",
    "    - promo_discount_2\n",
    "    - promo_discount_type_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'file_name': 'sales_data',\n",
       " 'inbound_delimiter': ',',\n",
       " 'columns': ['product_id',\n",
       "  'store_id',\n",
       "  'date',\n",
       "  'sales',\n",
       "  'revenue',\n",
       "  'stock',\n",
       "  'price',\n",
       "  'promo_type_1',\n",
       "  'promo_bin_1',\n",
       "  'promo_type_2',\n",
       "  'promo_bin_2',\n",
       "  'promo_discount_2',\n",
       "  'promo_discount_type_2']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import testutility as util\n",
    "config_data = util.read_config_file(\"file.yaml\")\n",
    "config_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the file dinamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raghad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (10,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>revenue</th>\n",
       "      <th>stock</th>\n",
       "      <th>price</th>\n",
       "      <th>promo_type_1</th>\n",
       "      <th>promo_bin_1</th>\n",
       "      <th>promo_type_2</th>\n",
       "      <th>promo_bin_2</th>\n",
       "      <th>promo_discount_2</th>\n",
       "      <th>promo_discount_type_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0002</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>PR14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0012</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>PR14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0013</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>PR14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0023</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>PR14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0025</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>PR14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id store_id        date  sales  revenue  stock  price promo_type_1  \\\n",
       "0      P0001    S0002  2017-01-02    0.0     0.00    8.0   6.25         PR14   \n",
       "1      P0001    S0012  2017-01-02    1.0     5.30    0.0   6.25         PR14   \n",
       "2      P0001    S0013  2017-01-02    2.0    10.59    0.0   6.25         PR14   \n",
       "3      P0001    S0023  2017-01-02    0.0     0.00    6.0   6.25         PR14   \n",
       "4      P0001    S0025  2017-01-02    0.0     0.00    1.0   6.25         PR14   \n",
       "\n",
       "  promo_bin_1 promo_type_2 promo_bin_2  promo_discount_2 promo_discount_type_2  \n",
       "0         NaN         PR03         NaN               NaN                   NaN  \n",
       "1         NaN         PR03         NaN               NaN                   NaN  \n",
       "2         NaN         PR03         NaN               NaN                   NaN  \n",
       "3         NaN         PR03         NaN               NaN                   NaN  \n",
       "4         NaN         PR03         NaN               NaN                   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file using config file\n",
    "file_type = config_data['file_type']\n",
    "source_file = \"./\" + config_data['file_name'] + f'.{file_type}'\n",
    "df = pd.read_csv(source_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamically Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.col_header_val(df ,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns of files are: Index(['product_id', 'store_id', 'date', 'sales', 'revenue', 'stock', 'price',\n",
      "       'promo_type_1', 'promo_bin_1', 'promo_type_2', 'promo_bin_2',\n",
      "       'promo_discount_2', 'promo_discount_type_2'],\n",
      "      dtype='object')\n",
      "columns of YAML are: ['product_id', 'store_id', 'date', 'sales', 'revenue', 'stock', 'price', 'promo_type_1', 'promo_bin_1', 'promo_type_2', 'promo_bin_2', 'promo_discount_2', 'promo_discount_type_2']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns of files are:\" ,df.columns)\n",
    "print(\"columns of YAML are:\" ,config_data['columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we have the same columns on both files, the validation passed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the file in pipe separated text file (|) in gz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "\n",
    "# Write csv in gz format in pipe separated text file (|)\n",
    "df.to_csv('sales_data.csv.gz',\n",
    "          sep='|',\n",
    "          header=True,\n",
    "          index=False,\n",
    "          quoting=csv.QUOTE_ALL,\n",
    "          compression='gzip',\n",
    "          line_terminator='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of rows:  19454838\n",
      "The number of columns:  13\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19454838 entries, 0 to 19454837\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   product_id             object \n",
      " 1   store_id               object \n",
      " 2   date                   object \n",
      " 3   sales                  float64\n",
      " 4   revenue                float64\n",
      " 5   stock                  float64\n",
      " 6   price                  float64\n",
      " 7   promo_type_1           object \n",
      " 8   promo_bin_1            object \n",
      " 9   promo_type_2           object \n",
      " 10  promo_bin_2            object \n",
      " 11  promo_discount_2       float64\n",
      " 12  promo_discount_type_2  object \n",
      "dtypes: float64(5), object(8)\n",
      "memory usage: 1.9+ GB\n",
      "File Size is : 1064515532 bytes\n"
     ]
    }
   ],
   "source": [
    "#Total number of rows of the file: \n",
    "print(\"The total number of rows: \", df.shape[0])\n",
    "#Total number of columns of the file:\n",
    "print(\"The number of columns: \", df.shape[1])\n",
    "df.info()\n",
    "print(\"File Size is :\", os.path.getsize('sales_data.csv'), \"bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
